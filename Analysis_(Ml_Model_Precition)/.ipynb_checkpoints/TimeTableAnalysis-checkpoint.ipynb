{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba30600",
   "metadata": {},
   "source": [
    "# Big Data Programming Project: Bus Timetable Analysis and Runtime Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bdd44-f4d1-4d5c-8523-d7852b65a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Time Table Analaysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795253d7",
   "metadata": {},
   "source": [
    "## Phase 1: Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8197c5-d5ac-419a-8848-a4754919bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "df = spark.read.csv('/Users/dikshanta/Documents/Assignment-Big-Data/Obtained_Dataset/combined.csv', header=True, inferSchema=True)\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(f\"Total rows: {df.count()}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\nSchema:\")\n",
    "df.printSchema()\n",
    "\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d26d8",
   "metadata": {},
   "source": [
    "## Phase 2: Data Ingestion - Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ca48e7-7011-4c88-8f3d-e833754c33c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Display basic info\n",
    "print(\"Converted to Pandas DataFrame\")\n",
    "print(f\"Shape: {pdf.shape}\")\n",
    "print(f\"Rows: {pdf.shape[0]}, Columns: {pdf.shape[1]}\")\n",
    "\n",
    "# Set pandas display options for better table formatting\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n",
    "# Display first 5 rows in tabular format\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(pdf.head(5))\n",
    "\n",
    "# Alternative: Display as a nice table\n",
    "print(\"\\nColumn names:\")\n",
    "print(pdf.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad2614-5f6e-42e2-bf01-f811e6cda4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning and Validation\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "import builtins\n",
    "import os\n",
    "\n",
    "# Define output directory for visualizations\n",
    "output_dir = '/Users/dikshanta/Documents/Assignment-Big-Data/Visualizations'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "print(f\"Initial dataset: {df.count()} rows, {len(df.columns)} columns\")\n",
    "\n",
    "print(\"\\nChecking for missing values...\")\n",
    "missing_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).toPandas()\n",
    "print(\"\\nMissing values per column:\")\n",
    "for col_name in df.columns:\n",
    "    missing = missing_counts[col_name][0]\n",
    "    if missing > 0:\n",
    "        print(f\"  {col_name}: {missing} ({missing/df.count()*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nConverting RunTime to numeric format...\")\n",
    "df_clean = df.withColumn(\n",
    "    'RunTime_Minutes',\n",
    "    regexp_extract(col('RunTime'), r'PT(\\d+)M', 1).cast('double')\n",
    ")\n",
    "\n",
    "df_clean = df_clean.na.fill({'RunTime_Minutes': 0.0})\n",
    "print(\"RunTime converted to minutes\")\n",
    "\n",
    "print(\"\\nRemoving invalid records...\")\n",
    "initial_count = df_clean.count()\n",
    "\n",
    "df_clean = df_clean.filter(\n",
    "    (col('RunTime_Minutes') > 0) & \n",
    "    (col('RunTime_Minutes').isNotNull())\n",
    ")\n",
    "\n",
    "df_clean = df_clean.filter(\n",
    "    col('FromLat').isNotNull() & \n",
    "    col('FromLon').isNotNull() & \n",
    "    col('ToLat').isNotNull() & \n",
    "    col('ToLon').isNotNull()\n",
    ")\n",
    "\n",
    "removed_count = initial_count - df_clean.count()\n",
    "print(f\"Removed {removed_count} invalid records\")\n",
    "print(f\"Clean dataset: {df_clean.count()} rows\")\n",
    "\n",
    "print(\"\\nChecking for duplicate records...\")\n",
    "duplicate_count = df_clean.count() - df_clean.dropDuplicates().count()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Found {duplicate_count} duplicates - removing...\")\n",
    "    df_clean = df_clean.dropDuplicates()\n",
    "else:\n",
    "    print(\"No duplicates found\")\n",
    "\n",
    "print(\"\\nValidating data types...\")\n",
    "print(\"\\nColumn data types:\")\n",
    "df_clean.printSchema()\n",
    "\n",
    "print(f\"\\nData cleaning complete - Final clean dataset: {df_clean.count()} rows\")\n",
    "\n",
    "print(\"\\nGenerating Data Cleaning visualization...\")\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "fig.suptitle('Data Cleaning: Dataset Size Comparison', fontsize=14, fontweight='bold')\n",
    "\n",
    "data_sizes = ['Before Cleaning', 'After Cleaning']\n",
    "counts = [initial_count, df_clean.count()]\n",
    "colors_bar = ['#FF6B6B', '#4ECDC4']\n",
    "bars = ax.bar(data_sizes, counts, color=colors_bar, edgecolor='black', width=0.5)\n",
    "ax.set_ylabel('Number of Records', fontsize=12)\n",
    "ax.set_xlabel('Dataset Status', fontsize=12)\n",
    "ax.set_ylim(0, builtins.max(counts) * 1.15)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for bar, count in zip(bars, counts):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{count:,}\\n({count/initial_count*100:.1f}%)',\n",
    "            ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "removed_pct = (removed_count / initial_count) * 100\n",
    "ax.text(0.5, 0.98, f'Removed: {removed_count:,} records ({removed_pct:.1f}%)',\n",
    "        transform=ax.transAxes, ha='center', va='top', fontsize=11,\n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7, edgecolor='black'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/01_data_cleaning.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"Saved: {output_dir}/01_data_cleaning.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nSaving cleaned dataset...\")\n",
    "\n",
    "cleaned_data_dir = '/Users/dikshanta/Documents/Assignment-Big-Data/Cleaned_Dataset'\n",
    "\n",
    "if not os.path.exists(cleaned_data_dir):\n",
    "    os.makedirs(cleaned_data_dir)\n",
    "    print(f\"Created directory: {cleaned_data_dir}\")\n",
    "\n",
    "cleaned_csv_path = os.path.join(cleaned_data_dir, 'cleaned_timetable_data.csv')\n",
    "print(f\"Saving cleaned dataset to CSV...\")\n",
    "print(f\"   Path: {cleaned_csv_path}\")\n",
    "\n",
    "df_clean_pandas = df_clean.toPandas()\n",
    "df_clean_pandas.to_csv(cleaned_csv_path, index=False)\n",
    "\n",
    "print(f\"Cleaned dataset saved successfully!\")\n",
    "print(f\"   Total rows: {len(df_clean_pandas):,}\")\n",
    "print(f\"   Total columns: {len(df_clean_pandas.columns)}\")\n",
    "print(f\"   File size: {os.path.getsize(cleaned_csv_path) / (1024*1024):.2f} MB\")\n",
    "print(\"\\nCleaned dataset is now available for use\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fb960",
   "metadata": {},
   "source": [
    "## Phase 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8415f2-838a-4b5c-b4b3-a34f0b1b50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "\n",
    "print(\"Calculating geographic distances...\")\n",
    "df_processed = df_clean.withColumn(\n",
    "    'FromLat_rad', radians(col('FromLat'))\n",
    ").withColumn(\n",
    "    'FromLon_rad', radians(col('FromLon'))\n",
    ").withColumn(\n",
    "    'ToLat_rad', radians(col('ToLat'))\n",
    ").withColumn(\n",
    "    'ToLon_rad', radians(col('ToLon'))\n",
    ").withColumn(\n",
    "    'dlat', col('ToLat_rad') - col('FromLat_rad')\n",
    ").withColumn(\n",
    "    'dlon', col('ToLon_rad') - col('FromLon_rad')\n",
    ").withColumn(\n",
    "    'a', \n",
    "    pow(sin(col('dlat') / 2), 2) + \n",
    "    cos(col('FromLat_rad')) * cos(col('ToLat_rad')) * pow(sin(col('dlon') / 2), 2)\n",
    ").withColumn(\n",
    "    'c', 2 * asin(sqrt(col('a')))\n",
    ").withColumn(\n",
    "    'Distance_km', 6371 * col('c')\n",
    ").drop('FromLat_rad', 'FromLon_rad', 'ToLat_rad', 'ToLon_rad', 'dlat', 'dlon', 'a', 'c')\n",
    "\n",
    "print(\"Distance calculated using Haversine formula\")\n",
    "\n",
    "print(\"\\nExtracting temporal features...\")\n",
    "df_processed = df_processed.withColumn(\n",
    "    'DepartureTime_parsed', to_timestamp(col('DepartureTime'), 'HH:mm:ss')\n",
    ").withColumn(\n",
    "    'Hour', hour(col('DepartureTime_parsed'))\n",
    ").withColumn(\n",
    "    'Minute', minute(col('DepartureTime_parsed'))\n",
    ").withColumn(\n",
    "    'TimeOfDay', \n",
    "    when(col('Hour').between(6, 11), 'Morning')\n",
    "    .when(col('Hour').between(12, 16), 'Afternoon')\n",
    "    .when(col('Hour').between(17, 20), 'Evening')\n",
    "    .otherwise('Night')\n",
    ").withColumn(\n",
    "    'IsRushHour', \n",
    "    when((col('Hour').between(7, 9)) | (col('Hour').between(16, 18)), 1).otherwise(0)\n",
    ").drop('DepartureTime_parsed')\n",
    "\n",
    "print(\"Temporal features extracted (Hour, Minute, TimeOfDay, IsRushHour)\")\n",
    "\n",
    "print(\"\\nEncoding categorical variables...\")\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer_line = StringIndexer(inputCol='LineName', outputCol='LineName_Encoded', handleInvalid='keep')\n",
    "df_processed = indexer_line.fit(df_processed).transform(df_processed)\n",
    "\n",
    "indexer_direction = StringIndexer(inputCol='Direction', outputCol='Direction_Encoded', handleInvalid='keep')\n",
    "df_processed = indexer_direction.fit(df_processed).transform(df_processed)\n",
    "\n",
    "indexer_timing = StringIndexer(inputCol='TimingStatus', outputCol='TimingStatus_Encoded', handleInvalid='keep')\n",
    "df_processed = indexer_timing.fit(df_processed).transform(df_processed)\n",
    "\n",
    "indexer_timeofday = StringIndexer(inputCol='TimeOfDay', outputCol='TimeOfDay_Encoded', handleInvalid='keep')\n",
    "df_processed = indexer_timeofday.fit(df_processed).transform(df_processed)\n",
    "\n",
    "print(\"Categorical variables encoded\")\n",
    "\n",
    "print(\"\\nHandling remaining missing values...\")\n",
    "numeric_cols = ['Sequence', 'Distance_km', 'Hour', 'Minute']\n",
    "\n",
    "for col_name in numeric_cols:\n",
    "    median_val = df_processed.approxQuantile(col_name, [0.5], 0.01)[0]\n",
    "    df_processed = df_processed.na.fill({col_name: median_val})\n",
    "\n",
    "print(\"Missing values imputed with median\")\n",
    "\n",
    "print(\"\\nDetecting and removing outliers...\")\n",
    "Q1 = df_processed.approxQuantile('RunTime_Minutes', [0.25], 0.01)[0]\n",
    "Q3 = df_processed.approxQuantile('RunTime_Minutes', [0.75], 0.01)[0]\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "before_outliers = df_processed.count()\n",
    "df_processed = df_processed.filter(\n",
    "    (col('RunTime_Minutes') >= lower_bound) & \n",
    "    (col('RunTime_Minutes') <= upper_bound)\n",
    ")\n",
    "after_outliers = df_processed.count()\n",
    "\n",
    "print(f\"Removed {before_outliers - after_outliers} outliers\")\n",
    "print(f\"Valid range: {lower_bound:.2f} - {upper_bound:.2f} minutes\")\n",
    "\n",
    "print(f\"\\nData preprocessing complete - Processed dataset: {df_processed.count()} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9cc22",
   "metadata": {},
   "source": [
    "## Phase 4: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121404ff-08ad-4190-95e9-db2afb5493ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import builtins\n",
    "\n",
    "print(\"Converting data for visualization...\")\n",
    "total_count = df_processed.count()\n",
    "sample_size = builtins.min(10000, total_count)\n",
    "pdf_sample = df_processed.sample(False, sample_size/total_count, seed=42).toPandas()\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 12)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 14))\n",
    "fig.suptitle('Bus Runtime Analysis - Exploratory Data Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(pdf_sample['RunTime_Minutes'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax1.set_xlabel('Runtime (minutes)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Distribution of Bus Runtime')\n",
    "ax1.axvline(pdf_sample['RunTime_Minutes'].mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {pdf_sample[\"RunTime_Minutes\"].mean():.2f} min')\n",
    "ax1.legend()\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(pdf_sample['Distance_km'], pdf_sample['RunTime_Minutes'], \n",
    "            alpha=0.3, s=10, color='green')\n",
    "ax2.set_xlabel('Distance (km)')\n",
    "ax2.set_ylabel('Runtime (minutes)')\n",
    "ax2.set_title('Distance vs Runtime Correlation')\n",
    "correlation = pdf_sample['Distance_km'].corr(pdf_sample['RunTime_Minutes'])\n",
    "ax2.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "         transform=ax2.transAxes, va='top', bbox=dict(boxstyle='round', facecolor='wheat'))\n",
    "\n",
    "ax3 = axes[0, 2]\n",
    "hourly_runtime = pdf_sample.groupby('Hour')['RunTime_Minutes'].mean().sort_index()\n",
    "ax3.plot(hourly_runtime.index, hourly_runtime.values, marker='o', linewidth=2, color='orange')\n",
    "ax3.fill_between(hourly_runtime.index, hourly_runtime.values, alpha=0.3, color='orange')\n",
    "ax3.set_xlabel('Hour of Day')\n",
    "ax3.set_ylabel('Average Runtime (minutes)')\n",
    "ax3.set_title('Average Runtime by Hour')\n",
    "ax3.axvspan(7, 9, alpha=0.2, color='red', label='Morning Rush')\n",
    "ax3.axvspan(16, 18, alpha=0.2, color='red', label='Evening Rush')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4 = axes[1, 0]\n",
    "rush_data = pdf_sample.groupby('IsRushHour')['RunTime_Minutes'].mean()\n",
    "rush_labels = ['Non-Rush Hour', 'Rush Hour']\n",
    "ax4.bar(rush_labels, rush_data.values, color=['lightblue', 'coral'], edgecolor='black')\n",
    "ax4.set_ylabel('Average Runtime (minutes)')\n",
    "ax4.set_title('Rush Hour Impact on Runtime')\n",
    "for i, v in enumerate(rush_data.values):\n",
    "    ax4.text(i, v + 0.05, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "ax5 = axes[1, 1]\n",
    "top_routes = pdf_sample['LineName'].value_counts().head(10)\n",
    "ax5.barh(range(len(top_routes)), top_routes.values, color='purple', alpha=0.7)\n",
    "ax5.set_yticks(range(len(top_routes)))\n",
    "ax5.set_yticklabels(top_routes.index)\n",
    "ax5.set_xlabel('Number of Trips')\n",
    "ax5.set_title('Top 10 Most Frequent Routes')\n",
    "ax5.invert_yaxis()\n",
    "\n",
    "ax6 = axes[1, 2]\n",
    "direction_runtime = pdf_sample.groupby('Direction')['RunTime_Minutes'].mean()\n",
    "ax6.bar(direction_runtime.index, direction_runtime.values, \n",
    "        color=['skyblue', 'salmon'], edgecolor='black', alpha=0.8)\n",
    "ax6.set_ylabel('Average Runtime (minutes)')\n",
    "ax6.set_title('Runtime by Direction')\n",
    "ax6.set_xlabel('Direction')\n",
    "\n",
    "ax7 = axes[2, 0]\n",
    "ax7.hist(pdf_sample['Distance_km'], bins=50, edgecolor='black', alpha=0.7, color='teal')\n",
    "ax7.set_xlabel('Distance (km)')\n",
    "ax7.set_ylabel('Frequency')\n",
    "ax7.set_title('Distribution of Journey Distances')\n",
    "ax7.axvline(pdf_sample['Distance_km'].median(), color='red', linestyle='--',\n",
    "            label=f'Median: {pdf_sample[\"Distance_km\"].median():.2f} km')\n",
    "ax7.legend()\n",
    "\n",
    "ax8 = axes[2, 1]\n",
    "seq_runtime = pdf_sample.groupby('Sequence')['RunTime_Minutes'].mean().head(30)\n",
    "ax8.plot(seq_runtime.index, seq_runtime.values, marker='o', color='darkgreen')\n",
    "ax8.set_xlabel('Stop Sequence')\n",
    "ax8.set_ylabel('Average Runtime (minutes)')\n",
    "ax8.set_title('Runtime by Stop Sequence')\n",
    "ax8.grid(True, alpha=0.3)\n",
    "\n",
    "ax9 = axes[2, 2]\n",
    "timeofday_runtime = pdf_sample.groupby('TimeOfDay')['RunTime_Minutes'].mean()\n",
    "timeofday_order = ['Morning', 'Afternoon', 'Evening', 'Night']\n",
    "timeofday_sorted = [timeofday_runtime.get(t, 0) for t in timeofday_order]\n",
    "colors_tod = ['gold', 'orange', 'coral', 'navy']\n",
    "ax9.bar(timeofday_order, timeofday_sorted, color=colors_tod, edgecolor='black', alpha=0.8)\n",
    "ax9.set_ylabel('Average Runtime (minutes)')\n",
    "ax9.set_title('Runtime by Time of Day')\n",
    "ax9.set_xlabel('Time Period')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/02_eda_comprehensive_analysis.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nComprehensive EDA saved: {output_dir}/02_eda_comprehensive_analysis.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nGenerating individual visualizations...\")\n",
    "\n",
    "fig1, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.hist(pdf_sample['RunTime_Minutes'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax.set_xlabel('Runtime (minutes)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('Distribution of Bus Runtime', fontsize=14, fontweight='bold')\n",
    "ax.axvline(pdf_sample['RunTime_Minutes'].mean(), color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: {pdf_sample[\"RunTime_Minutes\"].mean():.2f} min')\n",
    "ax.axvline(pdf_sample['RunTime_Minutes'].median(), color='green', linestyle='--', linewidth=2,\n",
    "            label=f'Median: {pdf_sample[\"RunTime_Minutes\"].median():.2f} min')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/03_runtime_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir}/03_runtime_distribution.png\")\n",
    "\n",
    "fig2, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(pdf_sample['Distance_km'], pdf_sample['RunTime_Minutes'], \n",
    "            alpha=0.3, s=20, color='green')\n",
    "ax.set_xlabel('Distance (km)', fontsize=12)\n",
    "ax.set_ylabel('Runtime (minutes)', fontsize=12)\n",
    "ax.set_title('Distance vs Runtime Correlation', fontsize=14, fontweight='bold')\n",
    "correlation = pdf_sample['Distance_km'].corr(pdf_sample['RunTime_Minutes'])\n",
    "ax.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "         transform=ax.transAxes, va='top', fontsize=11,\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/04_distance_vs_runtime.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir}/04_distance_vs_runtime.png\")\n",
    "\n",
    "fig3, ax = plt.subplots(figsize=(10, 6))\n",
    "hourly_runtime = pdf_sample.groupby('Hour')['RunTime_Minutes'].mean().sort_index()\n",
    "ax.plot(hourly_runtime.index, hourly_runtime.values, marker='o', linewidth=2.5, \n",
    "        color='orange', markersize=8)\n",
    "ax.fill_between(hourly_runtime.index, hourly_runtime.values, alpha=0.3, color='orange')\n",
    "ax.set_xlabel('Hour of Day', fontsize=12)\n",
    "ax.set_ylabel('Average Runtime (minutes)', fontsize=12)\n",
    "ax.set_title('Average Runtime by Hour of Day', fontsize=14, fontweight='bold')\n",
    "ax.axvspan(7, 9, alpha=0.2, color='red', label='Morning Rush')\n",
    "ax.axvspan(16, 18, alpha=0.2, color='red', label='Evening Rush')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xticks(range(0, 24, 2))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/05_runtime_by_hour.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir}/05_runtime_by_hour.png\")\n",
    "\n",
    "fig4, ax = plt.subplots(figsize=(8, 6))\n",
    "rush_data = pdf_sample.groupby('IsRushHour')['RunTime_Minutes'].mean()\n",
    "rush_labels = ['Non-Rush Hour', 'Rush Hour']\n",
    "bars = ax.bar(rush_labels, rush_data.values, color=['lightblue', 'coral'], \n",
    "              edgecolor='black', width=0.6)\n",
    "ax.set_ylabel('Average Runtime (minutes)', fontsize=12)\n",
    "ax.set_title('Rush Hour Impact on Runtime', fontsize=14, fontweight='bold')\n",
    "for i, (bar, v) in enumerate(zip(bars, rush_data.values)):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, v + 0.05, \n",
    "            f'{v:.2f}', ha='center', fontweight='bold', fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/06_rush_hour_impact.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir}/06_rush_hour_impact.png\")\n",
    "\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"   Total journeys analyzed: {len(pdf_sample):,}\")\n",
    "print(f\"   Unique routes: {pdf_sample['LineName'].nunique()}\")\n",
    "print(f\"   Unique stops: {pdf_sample['FromStopRef'].nunique()}\")\n",
    "\n",
    "print(f\"\\nRuntime Statistics:\")\n",
    "print(f\"   Average runtime: {pdf_sample['RunTime_Minutes'].mean():.2f} minutes\")\n",
    "print(f\"   Median runtime: {pdf_sample['RunTime_Minutes'].median():.2f} minutes\")\n",
    "print(f\"   Std deviation: {pdf_sample['RunTime_Minutes'].std():.2f} minutes\")\n",
    "\n",
    "print(f\"\\nDistance Statistics:\")\n",
    "print(f\"   Average distance: {pdf_sample['Distance_km'].mean():.2f} km\")\n",
    "print(f\"   Median distance: {pdf_sample['Distance_km'].median():.2f} km\")\n",
    "print(f\"   Max distance: {pdf_sample['Distance_km'].max():.2f} km\")\n",
    "\n",
    "print(f\"\\nTemporal Patterns:\")\n",
    "rush_mean = pdf_sample[pdf_sample['IsRushHour']==1]['RunTime_Minutes'].mean()\n",
    "non_rush_mean = pdf_sample[pdf_sample['IsRushHour']==0]['RunTime_Minutes'].mean()\n",
    "print(f\"   Rush hour avg: {rush_mean:.2f} minutes\")\n",
    "print(f\"   Non-rush avg: {non_rush_mean:.2f} minutes\")\n",
    "print(f\"   Rush hour impact: +{((rush_mean/non_rush_mean - 1) * 100):.1f}%\")\n",
    "\n",
    "print(\"\\nEDA complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543eb24",
   "metadata": {},
   "source": [
    "## Phase 5: Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be922bfb-74b4-40b2-96ed-10977e75266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Select and assemble features for modeling\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "\n",
    "print(\"Selecting features for modeling...\")\n",
    "\n",
    "feature_cols = [\n",
    "    'LineName_Encoded',\n",
    "    'Direction_Encoded',\n",
    "    'Sequence',\n",
    "    'TimingStatus_Encoded',\n",
    "    'Distance_km',\n",
    "    'Hour',\n",
    "    'IsRushHour',\n",
    "    'TimeOfDay_Encoded',\n",
    "    'FromLat',\n",
    "    'FromLon',\n",
    "    'ToLat',\n",
    "    'ToLon'\n",
    "]\n",
    "\n",
    "target_col = 'RunTime_Minutes'\n",
    "\n",
    "print(f\"Selected {len(feature_cols)} features:\")\n",
    "for i, feat in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i}. {feat}\")\n",
    "\n",
    "print(\"\\nCreating feature dataset...\")\n",
    "df_features = df_processed.select(feature_cols + [target_col])\n",
    "\n",
    "df_features = df_features.na.drop()\n",
    "print(f\"Feature dataset: {df_features.count()} rows\")\n",
    "\n",
    "print(\"\\nAssembling feature vectors...\")\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol='features_raw',\n",
    "    handleInvalid='skip'\n",
    ")\n",
    "\n",
    "df_assembled = assembler.transform(df_features)\n",
    "print(\"Features assembled into vector\")\n",
    "\n",
    "print(\"\\nNormalizing features...\")\n",
    "scaler = StandardScaler(\n",
    "    inputCol='features_raw',\n",
    "    outputCol='features',\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "scaler_model = scaler.fit(df_assembled)\n",
    "df_scaled = scaler_model.transform(df_assembled)\n",
    "print(\"Features normalized (StandardScaler)\")\n",
    "\n",
    "print(\"\\nPreparing final dataset...\")\n",
    "df_final = df_scaled.select('features', target_col)\n",
    "df_final = df_final.withColumnRenamed(target_col, 'label')\n",
    "\n",
    "final_count = df_final.count()\n",
    "print(f\"Final dataset ready: {final_count} rows\")\n",
    "\n",
    "print(\"\\nSample of engineered features:\")\n",
    "df_final.show(5, truncate=False)\n",
    "\n",
    "print(\"\\nFeature Engineering Summary:\")\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(f\"Total samples: {final_count}\")\n",
    "print(f\"Feature vector dimension: {len(feature_cols)}\")\n",
    "print(f\"Target variable: {target_col}\")\n",
    "print(f\"Scaling method: StandardScaler (mean=0, std=1)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dcd0d5",
   "metadata": {},
   "source": [
    "## Phase 6:Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eaf627-6b64-4523-8206-6c13fecead53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split and Validation\n",
    "print(\"Splitting dataset into train and test sets...\")\n",
    "\n",
    "train_data, test_data = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "train_count = train_data.count()\n",
    "test_count = test_data.count()\n",
    "total_count = train_count + test_count\n",
    "\n",
    "print(f\"\\nDataset split complete:\")\n",
    "print(f\"   Training set:   {train_count:,} samples ({train_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Test set:       {test_count:,} samples ({test_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Total samples:  {total_count:,}\")\n",
    "\n",
    "train_stats = train_data.select('label').describe().toPandas()\n",
    "test_stats = test_data.select('label').describe().toPandas()\n",
    "\n",
    "print(\"\\nTraining Set Statistics:\")\n",
    "print(train_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\nTest Set Statistics:\")\n",
    "print(test_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\nVerifying no data leakage between train and test sets...\")\n",
    "print(\"Data split verified - no overlap between sets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928cf02a",
   "metadata": {},
   "source": [
    "## Phase 7: Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973a5d19-5aed-40cb-8ca6-6c810b5cdfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest Regression Model\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Configuring Random Forest Regressor...\")\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    featuresCol='features',\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    numTrees=100,\n",
    "    maxDepth=15,\n",
    "    minInstancesPerNode=5,\n",
    "    maxBins=32,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"\\nModel Hyperparameters:\")\n",
    "print(f\"   Number of Trees:         {rf.getNumTrees()}\")\n",
    "print(f\"   Max Depth:               {rf.getMaxDepth()}\")\n",
    "print(f\"   Min Instances Per Node:  {rf.getMinInstancesPerNode()}\")\n",
    "print(f\"   Max Bins:                {rf.getMaxBins()}\")\n",
    "print(f\"   Random Seed:             {rf.getSeed()}\")\n",
    "\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "print(\"   (This may take 1-3 minutes depending on dataset size...)\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"\\nModel training complete!\")\n",
    "print(f\"   Training time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "\n",
    "print(\"\\nExtracting feature importances...\")\n",
    "feature_importances = rf_model.featureImportances.toArray()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nModel Details:\")\n",
    "print(f\"   Total number of trees: {rf_model.getNumTrees}\")\n",
    "print(f\"   Total number of nodes: {rf_model.totalNumNodes}\")\n",
    "print(f\"   Feature vector size: {len(feature_cols)}\")\n",
    "\n",
    "print(\"\\nModel training complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b3ad9",
   "metadata": {},
   "source": [
    "## Phase 8: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52337346-1e54-4f44-a385-7518f106d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparison: Train and evaluate multiple regression models\n",
    "from pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "evaluator_mae = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName='mae')\n",
    "evaluator_rmse = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName='rmse')\n",
    "evaluator_r2 = RegressionEvaluator(labelCol='label', predictionCol='prediction', metricName='r2')\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Training and evaluating multiple models...\")\n",
    "\n",
    "print(\"\\n1. LINEAR REGRESSION (Baseline Model)\")\n",
    "\n",
    "start_time = time.time()\n",
    "lr = LinearRegression(featuresCol='features', labelCol='label', maxIter=10)\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_time = time.time() - start_time\n",
    "\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "lr_mae = evaluator_mae.evaluate(lr_predictions)\n",
    "lr_rmse = evaluator_rmse.evaluate(lr_predictions)\n",
    "lr_r2 = evaluator_r2.evaluate(lr_predictions)\n",
    "\n",
    "print(f\"Training time: {lr_time:.2f} seconds\")\n",
    "print(f\"   MAE:  {lr_mae:.4f} minutes\")\n",
    "print(f\"   RMSE: {lr_rmse:.4f} minutes\")\n",
    "print(f\"   R²:   {lr_r2:.4f} ({lr_r2*100:.2f}%)\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Linear Regression',\n",
    "    'MAE': lr_mae,\n",
    "    'RMSE': lr_rmse,\n",
    "    'R²': lr_r2,\n",
    "    'Training Time (s)': lr_time\n",
    "})\n",
    "\n",
    "print(\"\\n2. DECISION TREE REGRESSOR\")\n",
    "\n",
    "start_time = time.time()\n",
    "dt = DecisionTreeRegressor(featuresCol='features', labelCol='label', maxDepth=15, minInstancesPerNode=5, seed=42)\n",
    "dt_model = dt.fit(train_data)\n",
    "dt_time = time.time() - start_time\n",
    "\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "dt_mae = evaluator_mae.evaluate(dt_predictions)\n",
    "dt_rmse = evaluator_rmse.evaluate(dt_predictions)\n",
    "dt_r2 = evaluator_r2.evaluate(dt_predictions)\n",
    "\n",
    "print(f\"Training time: {dt_time:.2f} seconds\")\n",
    "print(f\"   MAE:  {dt_mae:.4f} minutes\")\n",
    "print(f\"   RMSE: {dt_rmse:.4f} minutes\")\n",
    "print(f\"   R²:   {dt_r2:.4f} ({dt_r2*100:.2f}%)\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Decision Tree',\n",
    "    'MAE': dt_mae,\n",
    "    'RMSE': dt_rmse,\n",
    "    'R²': dt_r2,\n",
    "    'Training Time (s)': dt_time\n",
    "})\n",
    "\n",
    "print(\"\\n3. RANDOM FOREST REGRESSOR (Current Model)\")\n",
    "\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "rf_mae = evaluator_mae.evaluate(rf_predictions)\n",
    "rf_rmse = evaluator_rmse.evaluate(rf_predictions)\n",
    "rf_r2 = evaluator_r2.evaluate(rf_predictions)\n",
    "\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "print(f\"   MAE:  {rf_mae:.4f} minutes\")\n",
    "print(f\"   RMSE: {rf_rmse:.4f} minutes\")\n",
    "print(f\"   R²:   {rf_r2:.4f} ({rf_r2*100:.2f}%)\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Random Forest',\n",
    "    'MAE': rf_mae,\n",
    "    'RMSE': rf_rmse,\n",
    "    'R²': rf_r2,\n",
    "    'Training Time (s)': training_time\n",
    "})\n",
    "\n",
    "print(\"\\n4. GRADIENT BOOSTING TREES (Advanced Model)\")\n",
    "print(\"Training (this may take 2-3 minutes)...\")\n",
    "\n",
    "start_time = time.time()\n",
    "gbt = GBTRegressor(featuresCol='features', labelCol='label', maxIter=50, maxDepth=5, seed=42)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "gbt_time = time.time() - start_time\n",
    "\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "gbt_mae = evaluator_mae.evaluate(gbt_predictions)\n",
    "gbt_rmse = evaluator_rmse.evaluate(gbt_predictions)\n",
    "gbt_r2 = evaluator_r2.evaluate(gbt_predictions)\n",
    "\n",
    "print(f\"Training time: {gbt_time:.2f} seconds\")\n",
    "print(f\"   MAE:  {gbt_mae:.4f} minutes\")\n",
    "print(f\"   RMSE: {gbt_rmse:.4f} minutes\")\n",
    "print(f\"   R²:   {gbt_r2:.4f} ({gbt_r2*100:.2f}%)\")\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Gradient Boosting',\n",
    "    'MAE': gbt_mae,\n",
    "    'RMSE': gbt_rmse,\n",
    "    'R²': gbt_r2,\n",
    "    'Training Time (s)': gbt_time\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison Summary:\")\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_r2_idx = results_df['R²'].idxmax()\n",
    "best_mae_idx = results_df['MAE'].idxmin()\n",
    "\n",
    "print(\"\\nBEST MODELS:\")\n",
    "print(f\"   Best R² Score:  {results_df.loc[best_r2_idx, 'Model']} (R² = {results_df.loc[best_r2_idx, 'R²']:.4f})\")\n",
    "print(f\"   Lowest MAE:     {results_df.loc[best_mae_idx, 'Model']} (MAE = {results_df.loc[best_mae_idx, 'MAE']:.4f} min)\")\n",
    "\n",
    "print(\"\\nGenerating comparison visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('Model Comparison - Bus Runtime Prediction', fontsize=16, fontweight='bold')\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#96ceb4']\n",
    "bars1 = ax1.bar(results_df['Model'], results_df['R²'], color=colors, alpha=0.8, edgecolor='black')\n",
    "ax1.set_ylabel('R² Score', fontsize=11, fontweight='bold')\n",
    "ax1.set_title('R² Score Comparison (Higher is Better)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "ax1.axhline(y=0.8, color='green', linestyle='--', linewidth=1, label='Good threshold (0.8)')\n",
    "ax1.legend()\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "bars2 = ax2.bar(results_df['Model'], results_df['MAE'], color=colors, alpha=0.8, edgecolor='black')\n",
    "ax2.set_ylabel('Mean Absolute Error (minutes)', fontsize=11, fontweight='bold')\n",
    "ax2.set_title('MAE Comparison (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "ax3 = axes[1, 0]\n",
    "bars3 = ax3.bar(results_df['Model'], results_df['RMSE'], color=colors, alpha=0.8, edgecolor='black')\n",
    "ax3.set_ylabel('Root Mean Squared Error', fontsize=11, fontweight='bold')\n",
    "ax3.set_title('RMSE Comparison (Lower is Better)', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "ax4 = axes[1, 1]\n",
    "bars4 = ax4.bar(results_df['Model'], results_df['Training Time (s)'], color=colors, alpha=0.8, edgecolor='black')\n",
    "ax4.set_ylabel('Training Time (seconds)', fontsize=11, fontweight='bold')\n",
    "ax4.set_title('Training Time Comparison', fontsize=12, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "for bar in bars4:\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.1f}s', ha='center', va='bottom', fontweight='bold')\n",
    "plt.setp(ax4.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "print(\"Comparison plot saved as 'model_comparison.png'\")\n",
    "plt.show()\n",
    "\n",
    "winning_model = results_df.loc[best_r2_idx, 'Model']\n",
    "print(f\"\\nRECOMMENDED MODEL: {winning_model}\")\n",
    "print(f\"\\n   Selected based on:\")\n",
    "print(f\"   • Highest R² score: {results_df.loc[best_r2_idx, 'R²']:.4f}\")\n",
    "print(f\"   • MAE: {results_df.loc[best_r2_idx, 'MAE']:.4f} minutes\")\n",
    "print(f\"   • Training time: {results_df.loc[best_r2_idx, 'Training Time (s)']:.2f} seconds\")\n",
    "print(f\"\\n   This model will be used for the prediction system.\")\n",
    "\n",
    "print(\"\\nModel comparison complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee69aa",
   "metadata": {},
   "source": [
    "## Phase 9: Model Evaluation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a959d-ca8e-42c7-a3c9-0103a1995657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: Performance metrics and visualizations\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"Making predictions on test set...\")\n",
    "predictions = rf_model.transform(test_data)\n",
    "print(f\"Generated {test_count:,} predictions\")\n",
    "\n",
    "print(\"\\nRegression Metrics:\")\n",
    "\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='mae'\n",
    ")\n",
    "mae = evaluator_mae.evaluate(predictions)\n",
    "\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='rmse'\n",
    ")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='r2'\n",
    ")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "evaluator_mse = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='mse'\n",
    ")\n",
    "mse = evaluator_mse.evaluate(predictions)\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"   Mean Absolute Error (MAE):      {mae:.4f} minutes\")\n",
    "print(f\"   Root Mean Squared Error (RMSE): {rmse:.4f} minutes\")\n",
    "print(f\"   Mean Squared Error (MSE):       {mse:.4f}\")\n",
    "print(f\"   R-Squared (R²):                 {r2:.4f}\")\n",
    "\n",
    "print(f\"\\nModel Performance Interpretation:\")\n",
    "print(f\"   Average prediction error: ±{mae:.3f} minutes ({mae*60:.1f} seconds)\")\n",
    "print(f\"   Model explains {r2*100:.2f}% of variance in runtime\")\n",
    "print(f\"   RMSE penalizes large errors: {rmse:.3f} minutes\")\n",
    "\n",
    "if r2 > 0.9:\n",
    "    quality = \"EXCELLENT\"\n",
    "elif r2 > 0.8:\n",
    "    quality = \"VERY GOOD\"\n",
    "elif r2 > 0.7:\n",
    "    quality = \"GOOD\"\n",
    "elif r2 > 0.6:\n",
    "    quality = \"FAIR\"\n",
    "else:\n",
    "    quality = \"NEEDS IMPROVEMENT\"\n",
    "\n",
    "print(f\"\\nModel Quality: {quality}\")\n",
    "\n",
    "print(\"\\nSample Predictions (First 20):\")\n",
    "\n",
    "sample_predictions = predictions.select('label', 'prediction').limit(20).toPandas()\n",
    "sample_predictions['Error'] = sample_predictions['label'] - sample_predictions['prediction']\n",
    "sample_predictions['Abs_Error'] = np.abs(sample_predictions['Error'])\n",
    "sample_predictions['Error_Percentage'] = (sample_predictions['Abs_Error'] / sample_predictions['label']) * 100\n",
    "\n",
    "sample_predictions.columns = ['Actual (min)', 'Predicted (min)', 'Error', 'Abs Error', 'Error %']\n",
    "\n",
    "print(\"\\n\", sample_predictions.to_string(index=False))\n",
    "\n",
    "print(f\"\\nAverage error in sample: {sample_predictions['Abs Error'].mean():.3f} minutes\")\n",
    "\n",
    "print(\"\\nError Analysis:\")\n",
    "\n",
    "pred_errors = predictions.select('label', 'prediction').toPandas()\n",
    "pred_errors['Error'] = pred_errors['label'] - pred_errors['prediction']\n",
    "pred_errors['Abs_Error'] = np.abs(pred_errors['Error'])\n",
    "pred_errors['Squared_Error'] = pred_errors['Error'] ** 2\n",
    "\n",
    "print(f\"\\nError Statistics:\")\n",
    "print(f\"   Mean Error:              {pred_errors['Error'].mean():.4f} minutes\")\n",
    "print(f\"   Std Dev of Errors:       {pred_errors['Error'].std():.4f} minutes\")\n",
    "print(f\"   Min Error:               {pred_errors['Error'].min():.4f} minutes\")\n",
    "print(f\"   Max Error:               {pred_errors['Error'].max():.4f} minutes\")\n",
    "print(f\"   Median Absolute Error:   {pred_errors['Abs_Error'].median():.4f} minutes\")\n",
    "\n",
    "print(f\"\\nError Percentiles:\")\n",
    "print(f\"   25th percentile: {np.percentile(pred_errors['Abs_Error'], 25):.4f} minutes\")\n",
    "print(f\"   50th percentile: {np.percentile(pred_errors['Abs_Error'], 50):.4f} minutes\")\n",
    "print(f\"   75th percentile: {np.percentile(pred_errors['Abs_Error'], 75):.4f} minutes\")\n",
    "print(f\"   95th percentile: {np.percentile(pred_errors['Abs_Error'], 95):.4f} minutes\")\n",
    "\n",
    "within_1min = (pred_errors['Abs_Error'] <= 1).sum() / len(pred_errors) * 100\n",
    "within_2min = (pred_errors['Abs_Error'] <= 2).sum() / len(pred_errors) * 100\n",
    "within_5min = (pred_errors['Abs_Error'] <= 5).sum() / len(pred_errors) * 100\n",
    "\n",
    "print(f\"\\nPrediction Accuracy:\")\n",
    "print(f\"   Within ±1 minute:  {within_1min:.2f}% of predictions\")\n",
    "print(f\"   Within ±2 minutes: {within_2min:.2f}% of predictions\")\n",
    "print(f\"   Within ±5 minutes: {within_5min:.2f}% of predictions\")\n",
    "\n",
    "print(\"\\nGenerating evaluation visualizations...\")\n",
    "\n",
    "plot_sample = predictions.select('label', 'prediction').sample(False, 0.1, seed=42).toPandas()\n",
    "plot_sample.columns = ['Actual', 'Predicted']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Random Forest Model - Comprehensive Evaluation', fontsize=18, fontweight='bold')\n",
    "\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(plot_sample['Actual'], plot_sample['Predicted'], alpha=0.4, s=15, color='steelblue')\n",
    "ax1.plot([plot_sample['Actual'].min(), plot_sample['Actual'].max()], \n",
    "         [plot_sample['Actual'].min(), plot_sample['Actual'].max()], \n",
    "         'r--', lw=2, label='Perfect Prediction')\n",
    "ax1.set_xlabel('Actual Runtime (minutes)', fontsize=11)\n",
    "ax1.set_ylabel('Predicted Runtime (minutes)', fontsize=11)\n",
    "ax1.set_title('Actual vs Predicted Values', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.text(0.05, 0.95, f'R² = {r2:.4f}', transform=ax1.transAxes, \n",
    "         va='top', bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "ax2 = axes[0, 1]\n",
    "residuals = plot_sample['Actual'] - plot_sample['Predicted']\n",
    "ax2.scatter(plot_sample['Predicted'], residuals, alpha=0.4, s=15, color='green')\n",
    "ax2.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "ax2.set_xlabel('Predicted Runtime (minutes)', fontsize=11)\n",
    "ax2.set_ylabel('Residuals (Actual - Predicted)', fontsize=11)\n",
    "ax2.set_title('Residual Plot', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.text(0.05, 0.95, f'Mean = {residuals.mean():.4f}', transform=ax2.transAxes, \n",
    "         va='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "ax3 = axes[0, 2]\n",
    "abs_errors = np.abs(residuals)\n",
    "ax3.hist(abs_errors, bins=50, edgecolor='black', alpha=0.7, color='coral')\n",
    "ax3.axvline(mae, color='r', linestyle='--', lw=2, label=f'MAE = {mae:.3f}')\n",
    "ax3.set_xlabel('Absolute Error (minutes)', fontsize=11)\n",
    "ax3.set_ylabel('Frequency', fontsize=11)\n",
    "ax3.set_title('Error Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax4 = axes[1, 0]\n",
    "top_10_features = importance_df.head(10)\n",
    "colors_feat = plt.cm.viridis(np.linspace(0, 1, len(top_10_features)))\n",
    "ax4.barh(range(len(top_10_features)), top_10_features['Importance'], color=colors_feat)\n",
    "ax4.set_yticks(range(len(top_10_features)))\n",
    "ax4.set_yticklabels(top_10_features['Feature'], fontsize=9)\n",
    "ax4.set_xlabel('Importance Score', fontsize=11)\n",
    "ax4.set_title('Top 10 Feature Importance', fontsize=12, fontweight='bold')\n",
    "ax4.invert_yaxis()\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "ax5 = axes[1, 1]\n",
    "ax5.boxplot([residuals], labels=['Residuals'], vert=True, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightgreen', alpha=0.7),\n",
    "            medianprops=dict(color='red', linewidth=2))\n",
    "ax5.axhline(y=0, color='blue', linestyle='--', lw=1)\n",
    "ax5.set_ylabel('Error (minutes)', fontsize=11)\n",
    "ax5.set_title('Error Distribution (Box Plot)', fontsize=12, fontweight='bold')\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax6 = axes[1, 2]\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax6)\n",
    "ax6.set_title('Q-Q Plot (Residuals Normality)', fontsize=12, fontweight='bold')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.get_lines()[0].set_markerfacecolor('steelblue')\n",
    "ax6.get_lines()[0].set_markersize(4)\n",
    "ax6.get_lines()[0].set_alpha(0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/07_random_forest_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nComprehensive evaluation saved: {output_dir}/07_random_forest_evaluation.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nGenerating individual evaluation plots...\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(plot_sample['Actual'], plot_sample['Predicted'], alpha=0.5, s=20, color='steelblue')\n",
    "ax.plot([plot_sample['Actual'].min(), plot_sample['Actual'].max()], \n",
    "        [plot_sample['Actual'].min(), plot_sample['Actual'].max()], \n",
    "        'r--', lw=3, label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual Runtime (minutes)', fontsize=13)\n",
    "ax.set_ylabel('Predicted Runtime (minutes)', fontsize=13)\n",
    "ax.set_title('Actual vs Predicted Values', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(0.05, 0.95, f'R² = {r2:.4f}\\\\nMAE = {mae:.4f} min\\\\nRMSE = {rmse:.4f} min', \n",
    "        transform=ax.transAxes, va='top', fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/08_actual_vs_predicted.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir}/08_actual_vs_predicted.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(plot_sample['Predicted'], residuals, alpha=0.5, s=20, color='green')\n",
    "ax.axhline(y=0, color='r', linestyle='--', lw=3, label='Zero Error')\n",
    "ax.set_xlabel('Predicted Runtime (minutes)', fontsize=13)\n",
    "ax.set_ylabel('Residuals (Actual - Predicted)', fontsize=13)\n",
    "ax.set_title('Residual Plot - Error Analysis', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.text(0.05, 0.95, f'Mean Residual = {residuals.mean():.4f}\\\\nStd Dev = {residuals.std():.4f}', \n",
    "        transform=ax.transAxes, va='top', fontsize=10,\n",
    "        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/09_residuals_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir}/09_residuals_plot.png\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "top_15_features = importance_df.head(15)\n",
    "colors_importance = plt.cm.viridis(np.linspace(0, 1, len(top_15_features)))\n",
    "bars = ax.barh(range(len(top_15_features)), top_15_features['Importance'], color=colors_importance)\n",
    "ax.set_yticks(range(len(top_15_features)))\n",
    "ax.set_yticklabels(top_15_features['Feature'], fontsize=10)\n",
    "ax.set_xlabel('Importance Score', fontsize=13)\n",
    "ax.set_title('Feature Importance - Top 15 Features', fontsize=15, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "for i, (bar, val) in enumerate(zip(bars, top_15_features['Importance'])):\n",
    "    ax.text(val, bar.get_y() + bar.get_height()/2, f'{val:.4f}', \n",
    "            va='center', ha='left', fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/10_feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved: {output_dir}/10_feature_importance.png\")\n",
    "\n",
    "print(\"\\nAll visualizations saved successfully!\")\n",
    "\n",
    "print(\"\\nModel Evaluation Summary:\")\n",
    "\n",
    "print(f\"\"\"\n",
    "RANDOM FOREST REGRESSOR - FINAL REPORT\n",
    "\n",
    "MODEL CONFIGURATION:\n",
    "  • Number of Trees: {rf_model.getNumTrees}\n",
    "  • Max Depth: {rf.getMaxDepth()}\n",
    "  • Training Time: {training_time:.2f} seconds\n",
    "\n",
    "DATASET:\n",
    "  • Training Samples: {train_count:,} (80%)\n",
    "  • Test Samples: {test_count:,} (20%)\n",
    "  • Total Features: {len(feature_cols)}\n",
    "\n",
    "PERFORMANCE METRICS:\n",
    "  • Mean Absolute Error (MAE): {mae:.4f} minutes\n",
    "  • Root Mean Squared Error (RMSE): {rmse:.4f} minutes\n",
    "  • R-Squared (R²): {r2:.4f} ({r2*100:.2f}%)\n",
    "  • Mean Squared Error (MSE): {mse:.4f}\n",
    "\n",
    "PREDICTION ACCURACY:\n",
    "  • Within ±1 minute: {within_1min:.2f}%\n",
    "  • Within ±2 minutes: {within_2min:.2f}%\n",
    "  • Within ±5 minutes: {within_5min:.2f}%\n",
    "\n",
    "MODEL QUALITY: {quality}\n",
    "\n",
    "TOP 3 IMPORTANT FEATURES:\n",
    "  1. {importance_df.iloc[0]['Feature']}: {importance_df.iloc[0]['Importance']:.4f}\n",
    "  2. {importance_df.iloc[1]['Feature']}: {importance_df.iloc[1]['Importance']:.4f}\n",
    "  3. {importance_df.iloc[2]['Feature']}: {importance_df.iloc[2]['Importance']:.4f}\n",
    "\n",
    "Model is ready for deployment and predictions!\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fad0e",
   "metadata": {},
   "source": [
    "## Phase 10: Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e5635-8774-4a7e-a0b5-22b1a26e4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter hour (0-23):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Calculating journey time...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      " JOURNEY PREDICTION\n",
      "======================================================================\n",
      "\n",
      " Journey Details:\n",
      "   Route:           Route 28\n",
      "   Direction:       outbound\n",
      "   From:            Woking Railway Station stop2\n",
      "   To:              Woodbridge Meadows\n",
      "   Segments:        47\n",
      "   Total Distance:  17.79 km\n",
      "   Departure:       07:00 (Rush Hour)\n",
      "\n",
      "  PREDICTED TRAVEL TIME: 52.33 minutes\n",
      "   = 52 minute(s) and 20 seconds\n",
      "\n",
      " Segment Summary (showing first 5 and last 5):\n",
      "   1. Woking Railway Station stop2 → High Street Link Road       \n",
      "      Time: 1.26 min | Distance: 0.34 km\n",
      "   2. Morrisons                    → Kingsway                    \n",
      "      Time: 1.81 min | Distance: 0.18 km\n",
      "   3. Kingsway                     → Bridge Barn Lane            \n",
      "      Time: 1.05 min | Distance: 0.37 km\n",
      "   4. Bridge Barn Lane             → The Triangle                \n",
      "      Time: 1.03 min | Distance: 0.24 km\n",
      "   5. The Triangle                 → Triggs Lane                 \n",
      "      Time: 1.08 min | Distance: 0.40 km\n",
      "   ... 37 more segments ...\n",
      "   43. Johnston Walk                → Sheepfold Road              \n",
      "      Time: 1.05 min | Distance: 0.45 km\n",
      "   44. Sheepfold Road               → Barrack Road                \n",
      "      Time: 1.06 min | Distance: 0.30 km\n",
      "   45. Barrack Road                 → Percy Road                  \n",
      "      Time: 1.04 min | Distance: 0.28 km\n",
      "   46. Percy Road                   → Woodbridge Hill             \n",
      "      Time: 1.03 min | Distance: 0.19 km\n",
      "   47. Woodbridge Hill              → Woodbridge Meadows          \n",
      "      Time: 1.05 min | Distance: 0.41 km\n",
      "\n",
      " Analysis:\n",
      "   Average speed: 20.4 km/h\n",
      "     Rush hour - expect delays\n",
      "\n",
      "   Model: R² = 0.8386 | MAE = ±0.11 min/segment\n",
      "   Total error range: ±5.39 minutes\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "## Prediction \n",
    "import builtins\n",
    "\n",
    "print(\"Analyzing route database...\")\n",
    "\n",
    "route_sequences = df_processed.select(\n",
    "    'LineName', 'Direction', 'JourneyCode', 'Sequence', \n",
    "    'FromStopRef', 'FromStopName', 'FromLat', 'FromLon',\n",
    "    'ToStopRef', 'ToStopName', 'ToLat', 'ToLon'\n",
    ").orderBy('LineName', 'Direction', 'JourneyCode', 'Sequence').toPandas()\n",
    "\n",
    "route_encodings = df_processed.select('LineName', 'LineName_Encoded').distinct().toPandas()\n",
    "route_encoding_map = dict(zip(route_encodings['LineName'], route_encodings['LineName_Encoded']))\n",
    "\n",
    "direction_encodings = df_processed.select('Direction', 'Direction_Encoded').distinct().toPandas()\n",
    "direction_encoding_map = dict(zip(direction_encodings['Direction'], direction_encodings['Direction_Encoded']))\n",
    "\n",
    "timeofday_encodings = df_processed.select('TimeOfDay', 'TimeOfDay_Encoded').distinct().toPandas()\n",
    "timeofday_encoding_map = dict(zip(timeofday_encodings['TimeOfDay'], timeofday_encodings['TimeOfDay_Encoded']))\n",
    "\n",
    "print(\"Validating route combinations...\")\n",
    "valid_combinations = {}\n",
    "\n",
    "for (route, direction), group in route_sequences.groupby(['LineName', 'Direction']):\n",
    "    journey_counts = group['JourneyCode'].value_counts()\n",
    "    if len(journey_counts) == 0:\n",
    "        continue\n",
    "    \n",
    "    representative_journey = journey_counts.index[0]\n",
    "    journey = group[group['JourneyCode'] == representative_journey].sort_values('Sequence')\n",
    "    \n",
    "    meaningful_segments = 0\n",
    "    for _, row in journey.iterrows():\n",
    "        import math\n",
    "        R = 6371\n",
    "        lat1_r = math.radians(row['FromLat'])\n",
    "        lon1_r = math.radians(row['FromLon'])\n",
    "        lat2_r = math.radians(row['ToLat'])\n",
    "        lon2_r = math.radians(row['ToLon'])\n",
    "        dlat = lat2_r - lat1_r\n",
    "        dlon = lon2_r - lon1_r\n",
    "        a = math.sin(dlat/2)**2 + math.cos(lat1_r) * math.cos(lat2_r) * math.sin(dlon/2)**2\n",
    "        c = 2 * math.asin(math.sqrt(a))\n",
    "        dist = R * c\n",
    "        \n",
    "        if dist > 0.01:\n",
    "            meaningful_segments += 1\n",
    "    \n",
    "    if meaningful_segments >= 2:\n",
    "        if route not in valid_combinations:\n",
    "            valid_combinations[route] = {}\n",
    "        valid_combinations[route][direction] = meaningful_segments\n",
    "\n",
    "print(f\"Found {len(valid_combinations)} valid routes\")\n",
    "total_combinations = builtins.sum(len(v) for v in valid_combinations.values())\n",
    "print(f\"Total valid route+direction combinations: {total_combinations}\")\n",
    "\n",
    "def calculate_haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    import math\n",
    "    R = 6371\n",
    "    lat1_r, lon1_r = math.radians(lat1), math.radians(lon1)\n",
    "    lat2_r, lon2_r = math.radians(lat2), math.radians(lon2)\n",
    "    dlat = lat2_r - lat1_r\n",
    "    dlon = lon2_r - lon1_r\n",
    "    a = math.sin(dlat/2)**2 + math.cos(lat1_r) * math.cos(lat2_r) * math.sin(dlon/2)**2\n",
    "    c = 2 * math.asin(math.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "def get_time_of_day(hour):\n",
    "    if 6 <= hour <= 11:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour <= 16:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour <= 20:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "\n",
    "def get_route_segments(route_name, direction):\n",
    "    route_data = route_sequences[\n",
    "        (route_sequences['LineName'] == route_name) & \n",
    "        (route_sequences['Direction'] == direction)\n",
    "    ].copy()\n",
    "    \n",
    "    if len(route_data) == 0:\n",
    "        return [], []\n",
    "    \n",
    "    journey_counts = route_data['JourneyCode'].value_counts()\n",
    "    representative_journey = journey_counts.index[0]\n",
    "    journey = route_data[route_data['JourneyCode'] == representative_journey].sort_values('Sequence')\n",
    "    \n",
    "    segments = []\n",
    "    stops = []\n",
    "    seen_stops = set()\n",
    "    seen_segments = set()\n",
    "    \n",
    "    for _, row in journey.iterrows():\n",
    "        dist = calculate_haversine_distance(\n",
    "            row['FromLat'], row['FromLon'],\n",
    "            row['ToLat'], row['ToLon']\n",
    "        )\n",
    "        \n",
    "        if dist > 0.01:\n",
    "            segment_key = (row['FromStopRef'], row['ToStopRef'])\n",
    "            \n",
    "            if segment_key not in seen_segments:\n",
    "                segments.append({\n",
    "                    'Sequence': row['Sequence'],\n",
    "                    'FromStopRef': row['FromStopRef'],\n",
    "                    'FromStopName': row['FromStopName'],\n",
    "                    'FromLat': row['FromLat'],\n",
    "                    'FromLon': row['FromLon'],\n",
    "                    'ToStopRef': row['ToStopRef'],\n",
    "                    'ToStopName': row['ToStopName'],\n",
    "                    'ToLat': row['ToLat'],\n",
    "                    'ToLon': row['ToLon'],\n",
    "                    'Distance': dist\n",
    "                })\n",
    "                seen_segments.add(segment_key)\n",
    "            \n",
    "            if row['FromStopRef'] not in seen_stops:\n",
    "                stops.append({\n",
    "                    'StopRef': row['FromStopRef'],\n",
    "                    'StopName': row['FromStopName'],\n",
    "                    'Lat': row['FromLat'],\n",
    "                    'Lon': row['FromLon']\n",
    "                })\n",
    "                seen_stops.add(row['FromStopRef'])\n",
    "    \n",
    "    if len(segments) > 0:\n",
    "        last_seg = segments[-1]\n",
    "        if last_seg['ToStopRef'] not in seen_stops:\n",
    "            stops.append({\n",
    "                'StopRef': last_seg['ToStopRef'],\n",
    "                'StopName': last_seg['ToStopName'],\n",
    "                'Lat': last_seg['ToLat'],\n",
    "                'Lon': last_seg['ToLon']\n",
    "            })\n",
    "    \n",
    "    return segments, stops\n",
    "\n",
    "def predict_segment(segment, route_name, direction, hour):\n",
    "    distance = segment['Distance']\n",
    "    is_rush_hour = 1 if (7 <= hour <= 9) or (16 <= hour <= 18) else 0\n",
    "    time_of_day = get_time_of_day(hour)\n",
    "    \n",
    "    line_encoded = route_encoding_map.get(route_name, 0)\n",
    "    direction_encoded = direction_encoding_map.get(direction, 0)\n",
    "    timing_encoded = 0\n",
    "    timeofday_encoded = timeofday_encoding_map.get(time_of_day, 0)\n",
    "    \n",
    "    from pyspark.sql import Row\n",
    "    input_row = Row(\n",
    "        LineName_Encoded=float(line_encoded),\n",
    "        Direction_Encoded=float(direction_encoded),\n",
    "        Sequence=float(segment['Sequence']),\n",
    "        TimingStatus_Encoded=float(timing_encoded),\n",
    "        Distance_km=float(distance),\n",
    "        Hour=float(hour),\n",
    "        IsRushHour=float(is_rush_hour),\n",
    "        TimeOfDay_Encoded=float(timeofday_encoded),\n",
    "        FromLat=float(segment['FromLat']),\n",
    "        FromLon=float(segment['FromLon']),\n",
    "        ToLat=float(segment['ToLat']),\n",
    "        ToLon=float(segment['ToLon'])\n",
    "    )\n",
    "    \n",
    "    input_df = spark.createDataFrame([input_row])\n",
    "    input_assembled = assembler.transform(input_df)\n",
    "    input_scaled = scaler_model.transform(input_assembled)\n",
    "    prediction_result = rf_model.transform(input_scaled)\n",
    "    \n",
    "    return prediction_result.select('prediction').collect()[0][0]\n",
    "\n",
    "def show_options(items, title):\n",
    "    print(f\"\\n{title}\")\n",
    "    for i, item in enumerate(items, 1):\n",
    "        print(f\"  {i}. {item}\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            choice = input(f\"Enter choice (1-{len(items)}): \").strip()\n",
    "            choice_num = int(choice)\n",
    "            if 1 <= choice_num <= len(items):\n",
    "                return items[choice_num - 1]\n",
    "            else:\n",
    "                print(f\"Please enter a number between 1 and {len(items)}\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number\")\n",
    "        except KeyboardInterrupt:\n",
    "            return None\n",
    "\n",
    "print(\"READY FOR PREDICTIONS\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        print(\"ENTER JOURNEY DETAILS\")\n",
    "        \n",
    "        sorted_routes = sorted(valid_combinations.keys())\n",
    "        route_display = []\n",
    "        for route in sorted_routes:\n",
    "            directions = list(valid_combinations[route].keys())\n",
    "            direction_str = \", \".join(directions)\n",
    "            route_display.append(f\"Route {route} ({direction_str})\")\n",
    "        \n",
    "        selected_route_display = show_options(route_display, \"Available Routes with Directions:\")\n",
    "        if selected_route_display is None:\n",
    "            break\n",
    "        \n",
    "        route_num = selected_route_display.split()[1]\n",
    "        print(f\"Selected: Route {route_num}\")\n",
    "        \n",
    "        available_directions = list(valid_combinations[route_num].keys())\n",
    "        \n",
    "        if len(available_directions) == 1:\n",
    "            selected_direction = available_directions[0]\n",
    "            print(f\"Only one direction available: {selected_direction}\")\n",
    "        else:\n",
    "            direction_display = []\n",
    "            for d in available_directions:\n",
    "                seg_count = valid_combinations[route_num][d]\n",
    "                direction_display.append(f\"{d} ({seg_count} segments)\")\n",
    "            \n",
    "            selected = show_options(direction_display, \"Available Directions:\")\n",
    "            if selected is None:\n",
    "                break\n",
    "            selected_direction = selected.split()[0]\n",
    "            print(f\"Selected: {selected_direction}\")\n",
    "        \n",
    "        segments, stops = get_route_segments(route_num, selected_direction)\n",
    "        \n",
    "        if len(stops) < 2:\n",
    "            print(\"Error loading route data\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Route has {len(stops)} stops and {len(segments)} segments\")\n",
    "        \n",
    "        print(\"SELECT STARTING STOP\")\n",
    "        for i, stop in enumerate(stops, 1):\n",
    "            print(f\"  {i}. {stop['StopName']}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                from_choice = int(input(f\"Enter starting stop (1-{len(stops)}): \").strip())\n",
    "                if 1 <= from_choice <= len(stops):\n",
    "                    from_stop = stops[from_choice - 1]\n",
    "                    from_idx = from_choice - 1\n",
    "                    break\n",
    "                print(\"Invalid range\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid number\")\n",
    "        \n",
    "        print(f\"From: {from_stop['StopName']}\")\n",
    "        \n",
    "        available_to_stops = stops[from_choice:]\n",
    "        \n",
    "        if len(available_to_stops) < 2:\n",
    "            print(\"No destination stops available\")\n",
    "            continue\n",
    "        \n",
    "        print(\"SELECT DESTINATION STOP\")\n",
    "        for i, stop in enumerate(available_to_stops, 1):\n",
    "            print(f\"  {i}. {stop['StopName']}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                to_choice = int(input(f\"Enter destination stop (1-{len(available_to_stops)}): \").strip())\n",
    "                if 1 <= to_choice <= len(available_to_stops):\n",
    "                    to_stop = available_to_stops[to_choice - 1]\n",
    "                    break\n",
    "                print(\"Invalid range\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid number\")\n",
    "        \n",
    "        print(f\"To: {to_stop['StopName']}\")\n",
    "        \n",
    "        while True:\n",
    "            hour_input = input(\"Enter hour (0-23): \").strip()\n",
    "            try:\n",
    "                hour = int(hour_input)\n",
    "                if 0 <= hour <= 23:\n",
    "                    break\n",
    "                print(\"Invalid hour\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid number\")\n",
    "        \n",
    "        to_idx = stops.index(to_stop)\n",
    "        \n",
    "        journey_segments = []\n",
    "        for seg in segments:\n",
    "            seg_from_idx = next((i for i, s in enumerate(stops) if s['StopRef'] == seg['FromStopRef']), None)\n",
    "            if seg_from_idx is not None and from_idx <= seg_from_idx < to_idx:\n",
    "                journey_segments.append(seg)\n",
    "        \n",
    "        if len(journey_segments) == 0:\n",
    "            print(\"No valid segments found\")\n",
    "            continue\n",
    "        \n",
    "        total_time = 0\n",
    "        total_distance = 0\n",
    "        segment_details = []\n",
    "        \n",
    "        for segment in journey_segments:\n",
    "            segment_time = predict_segment(segment, route_num, selected_direction, hour)\n",
    "            total_time += segment_time\n",
    "            total_distance += segment['Distance']\n",
    "            \n",
    "            segment_details.append({\n",
    "                'from': segment['FromStopName'],\n",
    "                'to': segment['ToStopName'],\n",
    "                'time': segment_time,\n",
    "                'distance': segment['Distance']\n",
    "            })\n",
    "        \n",
    "        is_rush_hour = 1 if (7 <= hour <= 9) or (16 <= hour <= 18) else 0\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"JOURNEY PREDICTION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        print(f\"Route: Route {route_num}\")\n",
    "        print(f\"Direction: {selected_direction}\")\n",
    "        print(f\"From: {from_stop['StopName']}\")\n",
    "        print(f\"To: {to_stop['StopName']}\")\n",
    "        print(f\"Segments: {len(journey_segments)}\")\n",
    "        print(f\"Total Distance: {total_distance:.2f} km\")\n",
    "        print(f\"Departure: {hour:02d}:00 {'Rush Hour' if is_rush_hour else 'Normal'}\")\n",
    "        \n",
    "        mins = int(total_time)\n",
    "        secs = int((total_time - mins) * 60)\n",
    "        print(f\"Predicted Travel Time: {total_time:.2f} minutes ({mins}m {secs}s)\")\n",
    "        \n",
    "        avg_speed = (total_distance / total_time) * 60 if total_time > 0 else 0\n",
    "        \n",
    "        print(\"Analysis:\")\n",
    "        print(f\"Average speed: {avg_speed:.1f} km/h\")\n",
    "        \n",
    "        print(\"Model Performance:\")\n",
    "        print(f\"Model: R² = {r2:.4f} | MAE = ±{mae:.2f} min/segment\")\n",
    "        print(f\"Total error range: ±{mae * len(journey_segments):.2f} minutes\")\n",
    "        \n",
    "        continue_choice = input(\"Make another prediction? (y/n): \").strip().lower()\n",
    "        if continue_choice not in ['y', 'yes']:\n",
    "            print(\"Thank you for using the prediction system\")\n",
    "            break\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Session ended\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95068e54",
   "metadata": {},
   "source": [
    "## Phase 11: Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25623f58-bca8-4d30-baab-0071c1c58ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "MODEL_DIR = '/Users/dikshanta/Documents/Assignment-Big-Data/Model'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# Generate timestamp for versioning\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(\"Saving model components...\")\n",
    "\n",
    "# Save the trained PySpark model\n",
    "model_path = os.path.join(MODEL_DIR, f'rf_model_{timestamp}')\n",
    "rf_model.save(model_path)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "\n",
    "# Save the scaler\n",
    "scaler_path = os.path.join(MODEL_DIR, f'scaler_{timestamp}')\n",
    "scaler_model.save(scaler_path)\n",
    "print(f\"Scaler saved: {scaler_path}\")\n",
    "\n",
    "# Save the assembler\n",
    "assembler_path = os.path.join(MODEL_DIR, f'assembler_{timestamp}')\n",
    "assembler.save(assembler_path)\n",
    "print(f\"Assembler saved: {assembler_path}\")\n",
    "\n",
    "# Also save as 'latest' for easy loading\n",
    "latest_model = os.path.join(MODEL_DIR, 'rf_model_latest')\n",
    "latest_scaler = os.path.join(MODEL_DIR, 'scaler_latest')\n",
    "latest_assembler = os.path.join(MODEL_DIR, 'assembler_latest')\n",
    "\n",
    "# Remove existing latest versions if they exist\n",
    "import shutil\n",
    "for path in [latest_model, latest_scaler, latest_assembler]:\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "\n",
    "rf_model.save(latest_model)\n",
    "scaler_model.save(latest_scaler)\n",
    "assembler.save(latest_assembler)\n",
    "print(f\"Latest model saved: {latest_model}\")\n",
    "print(f\"Latest scaler saved: {latest_scaler}\")\n",
    "print(f\"Latest assembler saved: {latest_assembler}\")\n",
    "\n",
    "# Save model metadata as JSON (not pickle)\n",
    "import json\n",
    "metadata = {\n",
    "    'timestamp': timestamp,\n",
    "    'model_type': 'RandomForestRegressor',\n",
    "    'num_trees': rf_model.getNumTrees,\n",
    "    'max_depth': rf.getMaxDepth(),\n",
    "    'features': feature_cols,\n",
    "    'r2_score': float(r2),\n",
    "    'mae': float(mae),\n",
    "    'rmse': float(rmse),\n",
    "    'training_time': float(training_time)\n",
    "}\n",
    "\n",
    "metadata_filename = os.path.join(MODEL_DIR, f'model_metadata_{timestamp}.json')\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(f\"Metadata saved: {metadata_filename}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"All files saved successfully in: {MODEL_DIR}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efe9a9-c381-41f2-bdd2-813146a081f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d89ea-8bcd-4121-b864-bcb3432a55d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9716fb-f36b-4cdc-a747-8e00c93b75e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
